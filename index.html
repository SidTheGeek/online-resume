<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Dennis Ivy</title>
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="./styles/main.css">
</head>
<body>
<div id="container--main">

    <section id="wrapper--hero" class="section--page">
        <img id="profile-pic" src="./assets/images/profile_pic.JPG">

        <div>
            <h1 id="user-name">SIDDHARTH NANDA</h1>
            <p id="bio">Big-Data developer with hands-on experience in Hadoop, Hive, Spark-ETL, SQL, Sqoop and Unix along with working experience in Agile.</p>
        </div>
    </section>

    <section class="section--page">

        <div id="socials--list">
            <a href="https://www.linkedin.com/in/siddharth-nanda/" target="_blank">Linkedin</a>
            <a href="https://github.com/SidTheGeek" target="_blank">Github</a>
            <a href="./assets/Siddharth_Nanda_BigData_5years_Resume.pdf" target="_blank">Download Resume</a>
        </div>
    </section>

    <section class="section--page">
        <h2>Skills & Qualifications</h2>
        <ul id="qualifications--list">
            <li>üîπ5.5 years of hands-on experience in Big-Data stack in Hadoop, Hive, Spark-ETL</li>
            <li>üîπÔ∏èExtensive knowledge in SQL, Sqoop and Unix.</li>
            <li>üîπWorking experience in Agile Methodologies</li>
        </ul>
    </section>

    <section class="section--page">
        <h2>Tech stack</h2>

        <div id="wrapper--techstack__items">
            <div class="card--techstack"><span>Hadoop, Hive, Sqoop, Spark</span></div>
            <div class="card--techstack"><span>Scala, Java</span></div>
            <div class="card--techstack"><span>IntelliJ IDEA, Eclipse, Putty, WinSCP, Git, Unix</span></div>
        </div>
    </section>

    <section id="work-history-wrapper" class="section--page">
        <h2>Work History</h2>

        <div class="card--work-history">
            <strong>üöß System Engineer | <i>Tata Consultancy Services, Bangalore</i></strong>
            <p><i>August 2021 ‚Äì Present</i></p>
            <p>Worked for a renowned banking client as Data Engineer working in various Big-Data tools</p>
            <ul>
                <li>Developed and maintained Spark-ETL and Ab Initio data pipelines within the Hadoop ecosystem.</li>
                <li>Loaded data into HIVE tables, implementing partitioned columns for efficient data management.</li>
                <li>Executed Data Extraction, Transformation, and Loading (ETL) processes across multiple HIVE tables.</li>
                <li>Applied data cleansing, JOINs, and filters on tabular data as per the BMT document.</li>
                <li>Employed optimization strategies and performance tuning on Hive tables to enhance processing efficiency.</li>
                <li>Created and managed Ab Initio pipelines, utilizing the Business Rule Engine (BRE) framework for seamless data transfer between Hive sources.</li>
                <li>Developed JIL files to schedule pipeline jobs using Autosys.</li>
                <li>Conducted rigorous Unit Testing and executed performance enhancements on HIVE tables.</li>

            </ul>
        </div>

        <div class="line-break"></div>

        <div class="card--work-history">
            <strong>üöß Programmer Analyst | <i>Cognizant Technology Solutions, Kolkata</i></strong>
            <p><i>March 2018 ‚Äì July 2021</i></p>
            <p>Worked for multiple insurance based clients as an Engineer working in various Big-Data tools</p>
            <ul>
                <li>Created an Ingestion pipeline to migrate data from source Relational Database to HDFS using Sqoop.</li>
                <li>Loaded data into HIVE tables with partitioned columns.</li>
                <li>Applied data cleansing, JOIN operations, and filtering techniques on tabular data to achieve desired outcomes as per the BRD.</li>
                <li>Performed Data cleanup and loaded the data from staging to Target table.</li>
                <li>Conducted rigorous Unit Testing and executed performance enhancements on HIVE tables.</li>
            </ul>
        </div>

    </section>
</div>
</body>
</html>